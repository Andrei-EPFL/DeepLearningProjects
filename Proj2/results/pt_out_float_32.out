Number in: 499.0, Number out: 501.0
Epoch 0: 
	Train loss: 2.60401629358530062319e-01	 Train acc: 0.48500000715255736639
	Val loss: 2.52878546714782714844e-01	 Val acc: 0.50499999523162841797
Epoch 1: 
	Train loss: 2.52489287853240984560e-01	 Train acc: 0.50900000624358654466
	Val loss: 2.48112425208091735840e-01	 Val acc: 0.50499999523162841797
Epoch 2: 
	Train loss: 2.43818712532520298630e-01	 Train acc: 0.56700000673532491291
	Val loss: 2.19080120325088500977e-01	 Val acc: 0.56699997186660766602
Epoch 3: 
	Train loss: 2.08907742127776158148e-01	 Train acc: 0.67800000585615638471
	Val loss: 1.52483254671096801758e-01	 Val acc: 0.78799998760223388672
Epoch 4: 
	Train loss: 1.81440484523773204462e-01	 Train acc: 0.74899999886751178479
	Val loss: 1.26379758119583129883e-01	 Val acc: 0.83899998664855957031
Epoch 5: 
	Train loss: 1.44949339665472520799e-01	 Train acc: 0.79699999630451201504
	Val loss: 8.94680544734001159668e-02	 Val acc: 0.91399997472763061523
Epoch 6: 
	Train loss: 1.35927441827952855125e-01	 Train acc: 0.82099999636411669091
	Val loss: 8.00622254610061645508e-02	 Val acc: 0.91500002145767211914
Epoch 7: 
	Train loss: 1.07162553220987319391e-01	 Train acc: 0.84999999523162839132
	Val loss: 6.46372213959693908691e-02	 Val acc: 0.96499997377395629883
Epoch 8: 
	Train loss: 9.23480108194053156412e-02	 Train acc: 0.88199999392032624179
	Val loss: 5.49614764750003814697e-02	 Val acc: 0.93699997663497924805
Epoch 9: 
	Train loss: 9.58963409159332563769e-02	 Train acc: 0.87599999666213990146
	Val loss: 7.68398046493530273438e-02	 Val acc: 0.89800000190734863281
Epoch 10: 
	Train loss: 8.81467832205817120039e-02	 Train acc: 0.89099999308586119717
	Val loss: 7.99867063760757446289e-02	 Val acc: 0.87999999523162841797
Epoch 11: 
	Train loss: 7.82421868294477518280e-02	 Train acc: 0.89599999368190763605
	Val loss: 6.84081241488456726074e-02	 Val acc: 0.91399997472763061523
Epoch 12: 
	Train loss: 7.34576074965298114750e-02	 Train acc: 0.90199999392032625956
	Val loss: 7.82347023487091064453e-02	 Val acc: 0.90299999713897705078
Epoch 13: 
	Train loss: 7.93689227476715997156e-02	 Train acc: 0.90299999535083774749
	Val loss: 4.60410155355930328369e-02	 Val acc: 0.94800001382827758789
Epoch 14: 
	Train loss: 7.07918456080369601358e-02	 Train acc: 0.91499999344348903474
	Val loss: 7.61822834610939025879e-02	 Val acc: 0.88300001621246337891
Epoch 15: 
	Train loss: 6.63618224253877952989e-02	 Train acc: 0.91899999082088468239
	Val loss: 5.34066446125507354736e-02	 Val acc: 0.94499999284744262695
Epoch 16: 
	Train loss: 6.73695552139542963577e-02	 Train acc: 0.91699999213218685856
	Val loss: 5.72262853384017944336e-02	 Val acc: 0.92500001192092895508
Epoch 17: 
	Train loss: 6.75152305397204999249e-02	 Train acc: 0.91499999105930329701
	Val loss: 5.56185916066169738770e-02	 Val acc: 0.93300002813339233398
Epoch 18: 
	Train loss: 6.52013202221132792680e-02	 Train acc: 0.91599999308586121938
	Val loss: 8.13222080469131469727e-02	 Val acc: 0.87000000476837158203
Epoch 19: 
	Train loss: 6.18127354513853810580e-02	 Train acc: 0.92099999308586122382
	Val loss: 8.96160975098609924316e-02	 Val acc: 0.87599998712539672852
Epoch 20: 
	Train loss: 6.68358954950235839565e-02	 Train acc: 0.90299999237060546431
	Val loss: 4.96078617870807647705e-02	 Val acc: 0.92900002002716064453
Epoch 21: 
	Train loss: 5.88204801653046185916e-02	 Train acc: 0.92299999296665191650
	Val loss: 3.29110994935035705566e-02	 Val acc: 0.96600002050399780273
Epoch 22: 
	Train loss: 5.82277309568598883116e-02	 Train acc: 0.92199999272823329743
	Val loss: 3.93611416220664978027e-02	 Val acc: 0.95099997520446777344
Epoch 23: 
	Train loss: 5.66938091139309111033e-02	 Train acc: 0.93399999201297756457
	Val loss: 6.17086961865425109863e-02	 Val acc: 0.90499997138977050781
Epoch 24: 
	Train loss: 5.62895895645488045234e-02	 Train acc: 0.92399999141693112126
	Val loss: 3.13937924802303314209e-02	 Val acc: 0.95999997854232788086
Epoch 25: 
	Train loss: 5.58373520406894377488e-02	 Train acc: 0.92499999165534974033
	Val loss: 4.65425178408622741699e-02	 Val acc: 0.93999999761581420898
Epoch 26: 
	Train loss: 4.58652019465807803122e-02	 Train acc: 0.93599999248981480271
	Val loss: 6.87852948904037475586e-02	 Val acc: 0.90200001001358032227
Epoch 27: 
	Train loss: 5.23556050099432471190e-02	 Train acc: 0.93199999094009400302
	Val loss: 5.35290390253067016602e-02	 Val acc: 0.91900002956390380859
Epoch 28: 
	Train loss: 5.44346674246480657922e-02	 Train acc: 0.92599999248981479383
	Val loss: 6.08847066760063171387e-02	 Val acc: 0.90899997949600219727
Epoch 29: 
	Train loss: 5.35266482608858507053e-02	 Train acc: 0.92599999010562894508
	Val loss: 3.74400727450847625732e-02	 Val acc: 0.95700001716613769531
Epoch 30: 
	Train loss: 4.77219413034617873093e-02	 Train acc: 0.93099999368190766713
	Val loss: 4.99054081737995147705e-02	 Val acc: 0.93300002813339233398
Epoch 31: 
	Train loss: 4.04722835827851651347e-02	 Train acc: 0.94899999320507044676
	Val loss: 6.80197253823280334473e-02	 Val acc: 0.90799999237060546875
Epoch 32: 
	Train loss: 5.20386222942033765948e-02	 Train acc: 0.93299999356269835982
	Val loss: 2.99893356859683990479e-02	 Val acc: 0.97100001573562622070
Epoch 33: 
	Train loss: 5.53070488420780714822e-02	 Train acc: 0.92999999284744261363
	Val loss: 4.39104214310646057129e-02	 Val acc: 0.95399999618530273438
Epoch 34: 
	Train loss: 4.90713621885515774435e-02	 Train acc: 0.93499999165534974921
	Val loss: 3.87364737689495086670e-02	 Val acc: 0.95999997854232788086
Epoch 35: 
	Train loss: 4.61887198092881604006e-02	 Train acc: 0.93999999284744262251
	Val loss: 4.90870364010334014893e-02	 Val acc: 0.94099998474121093750
Epoch 36: 
	Train loss: 4.33139597345143581575e-02	 Train acc: 0.94399999380111698777
	Val loss: 4.34313304722309112549e-02	 Val acc: 0.93999999761581420898
Epoch 37: 
	Train loss: 5.10317302518524251731e-02	 Train acc: 0.93699999332427974519
	Val loss: 2.78937108814716339111e-02	 Val acc: 0.96700000762939453125
Epoch 38: 
	Train loss: 4.94468633842188864946e-02	 Train acc: 0.93399999320507054446
	Val loss: 4.93524745106697082520e-02	 Val acc: 0.93500000238418579102
Epoch 39: 
	Train loss: 4.94927747658221034444e-02	 Train acc: 0.94199999213218688077
	Val loss: 5.55185377597808837891e-02	 Val acc: 0.92400002479553222656
Epoch 40: 
	Train loss: 4.49643284827470762766e-02	 Train acc: 0.94199998974800114304
	Val loss: 3.53700593113899230957e-02	 Val acc: 0.95300000905990600586
Epoch 41: 
	Train loss: 3.84145486936904520525e-02	 Train acc: 0.94999999344348906583
	Val loss: 2.71466262638568878174e-02	 Val acc: 0.96100002527236938477
Epoch 42: 
	Train loss: 5.09292445203755050898e-02	 Train acc: 0.93599999308586123714
	Val loss: 3.72065939009189605713e-02	 Val acc: 0.95099997520446777344
Epoch 43: 
	Train loss: 4.63312426221091297474e-02	 Train acc: 0.93499999225139618364
	Val loss: 4.11001481115818023682e-02	 Val acc: 0.94599997997283935547
Epoch 44: 
	Train loss: 4.78104362770682203565e-02	 Train acc: 0.94099999248981480715
	Val loss: 3.57172973453998565674e-02	 Val acc: 0.95800000429153442383
Epoch 45: 
	Train loss: 4.94318144459975905569e-02	 Train acc: 0.94099999368190767601
	Val loss: 3.54317575693130493164e-02	 Val acc: 0.95499998331069946289
Epoch 46: 
	Train loss: 3.78629385860404024666e-02	 Train acc: 0.94899999260902401232
	Val loss: 4.65689375996589660645e-02	 Val acc: 0.93900001049041748047
Epoch 47: 
	Train loss: 4.51498965523205730843e-02	 Train acc: 0.93999999284744262251
	Val loss: 4.00407500565052032471e-02	 Val acc: 0.95099997520446777344
Epoch 48: 
	Train loss: 3.83912845869781443886e-02	 Train acc: 0.95299999415874481201
	Val loss: 4.01285141706466674805e-02	 Val acc: 0.94900000095367431641
Epoch 49: 
	Train loss: 3.85953104312648093144e-02	 Train acc: 0.95599999248981470945
	Val loss: 5.38913197815418243408e-02	 Val acc: 0.92100000381469726562

==> End of training after 4.160580158233643 seconds. Generating a new test set

Final test loss: 0.046	Final test acc: 0.93	Final test error 0.07

Step=0: loss=-0.0028660192620009184
 Input before update:  tensor([0.882269263267517089843750000000, 0.915003955364227294921875000000],
       requires_grad=True)
Input after update:  tensor([0.880387485027313232421875000000, 0.912253320217132568359375000000],
       requires_grad=True)
Gradient with respect the input:  tensor([0.018817918375134468078613281250, 0.027506571263074874877929687500])

Step=1: loss=-0.0029782538767904043
 Input before update:  tensor([0.880387485027313232421875000000, 0.912253320217132568359375000000],
       requires_grad=True)
Input after update:  tensor([0.878464460372924804687500000000, 0.909445762634277343750000000000],
       requires_grad=True)
Gradient with respect the input:  tensor([0.019230246543884277343750000000, 0.028075620532035827636718750000])

Step=2: loss=-0.003095306223258376
 Input before update:  tensor([0.878464460372924804687500000000, 0.909445762634277343750000000000],
       requires_grad=True)
Input after update:  tensor([0.876497745513916015625000000000, 0.906578779220581054687500000000],
       requires_grad=True)
Gradient with respect the input:  tensor([0.019666897132992744445800781250, 0.028669679537415504455566406250])

Step=3: loss=-0.0032175262458622456
 Input before update:  tensor([0.876497745513916015625000000000, 0.906578779220581054687500000000],
       requires_grad=True)
Input after update:  tensor([0.874484360218048095703125000000, 0.903649389743804931640625000000],
       requires_grad=True)
Gradient with respect the input:  tensor([0.020133778452873229980468750000, 0.029293941333889961242675781250])

Step=4: loss=-0.003345344914123416
 Input before update:  tensor([0.874484360218048095703125000000, 0.903649389743804931640625000000],
       requires_grad=True)
Input after update:  tensor([0.872420489788055419921875000000, 0.900653839111328125000000000000],
       requires_grad=True)
Gradient with respect the input:  tensor([0.020638884976506233215332031250, 0.029955426231026649475097656250])

Step=5: loss=-0.0034792872611433268
 Input before update:  tensor([0.872420489788055419921875000000, 0.900653839111328125000000000000],
       requires_grad=True)
Input after update:  tensor([0.870301187038421630859375000000, 0.897587478160858154296875000000],
       requires_grad=True)
Gradient with respect the input:  tensor([0.021193161606788635253906250000, 0.030663698911666870117187500000])

Step=6: loss=-0.003620039438828826
 Input before update:  tensor([0.870301187038421630859375000000, 0.897587478160858154296875000000],
       requires_grad=True)
Input after update:  tensor([0.868120014667510986328125000000, 0.894444286823272705078125000000],
       requires_grad=True)
Gradient with respect the input:  tensor([0.021811828017234802246093750000, 0.031432062387466430664062500000])

Step=7: loss=-0.0037684778217226267
 Input before update:  tensor([0.868120014667510986328125000000, 0.894444286823272705078125000000],
       requires_grad=True)
Input after update:  tensor([0.865868389606475830078125000000, 0.891216397285461425781250000000],
       requires_grad=True)
Gradient with respect the input:  tensor([0.022516196593642234802246093750, 0.032279055565595626831054687500])

Step=8: loss=-0.003925784025341272
 Input before update:  tensor([0.865868389606475830078125000000, 0.891216397285461425781250000000],
       requires_grad=True)
Input after update:  tensor([0.863534688949584960937500000000, 0.887893259525299072265625000000],
       requires_grad=True)
Gradient with respect the input:  tensor([0.023336816579103469848632812500, 0.033231221139430999755859375000])

Step=9: loss=-0.004093577153980732
 Input before update:  tensor([0.863534688949584960937500000000, 0.887893259525299072265625000000],
       requires_grad=True)
Input after update:  tensor([0.861102879047393798828125000000, 0.884460568428039550781250000000],
       requires_grad=True)
Gradient with respect the input:  tensor([0.024318179115653038024902343750, 0.034327141940593719482421875000])

Step=10: loss=-0.004274145234376192
 Input before update:  tensor([0.861102879047393798828125000000, 0.884460568428039550781250000000],
       requires_grad=True)
Input after update:  tensor([0.858550190925598144531250000000, 0.880898118019104003906250000000],
       requires_grad=True)
Gradient with respect the input:  tensor([0.025526771321892738342285156250, 0.035624343901872634887695312500])

Step=11: loss=-0.0044708577916026115
 Input before update:  tensor([0.858550190925598144531250000000, 0.880898118019104003906250000000],
       requires_grad=True)
Input after update:  tensor([0.855843663215637207031250000000, 0.877176940441131591796875000000],
       requires_grad=True)
Gradient with respect the input:  tensor([0.027065388858318328857421875000, 0.037211623042821884155273437500])

Step=12: loss=-0.004688851069658995
 Input before update:  tensor([0.855843663215637207031250000000, 0.877176940441131591796875000000],
       requires_grad=True)
Input after update:  tensor([0.852933764457702636718750000000, 0.873253822326660156250000000000],
       requires_grad=True)
Gradient with respect the input:  tensor([0.029098976403474807739257812500, 0.039231106638908386230468750000])

Step=13: loss=-0.00493639474734664
 Input before update:  tensor([0.852933764457702636718750000000, 0.873253822326660156250000000000],
       requires_grad=True)
Input after update:  tensor([0.849743068218231201171875000000, 0.869061529636383056640625000000],
       requires_grad=True)
Gradient with respect the input:  tensor([0.031906791031360626220703125000, 0.041922941803932189941406250000])

Step=14: loss=-0.005227711051702499
 Input before update:  tensor([0.849743068218231201171875000000, 0.869061529636383056640625000000],
       requires_grad=True)
Input after update:  tensor([0.846143543720245361328125000000, 0.864489376544952392578125000000],
       requires_grad=True)
Gradient with respect the input:  tensor([0.035995151847600936889648437500, 0.045721501111984252929687500000])

Step=15: loss=-0.0055895415134727955
 Input before update:  tensor([0.846143543720245361328125000000, 0.864489376544952392578125000000],
       requires_grad=True)
Input after update:  tensor([0.841906368732452392578125000000, 0.859340488910675048828125000000],
       requires_grad=True)
Gradient with respect the input:  tensor([0.042371813207864761352539062500, 0.051489137113094329833984375000])

Step=16: loss=-0.006078952923417091
 Input before update:  tensor([0.841906368732452392578125000000, 0.859340488910675048828125000000],
       requires_grad=True)
Input after update:  tensor([0.836574077606201171875000000000, 0.853222787380218505859375000000],
       requires_grad=True)
Gradient with respect the input:  tensor([0.053322672843933105468750000000, 0.061176858842372894287109375000])

Step=17: loss=-0.0068434118293225765
 Input before update:  tensor([0.836574077606201171875000000000, 0.853222787380218505859375000000],
       requires_grad=True)
Input after update:  tensor([0.829096794128417968750000000000, 0.845231592655181884765625000000],
       requires_grad=True)
Gradient with respect the input:  tensor([0.074772953987121582031250000000, 0.079912059009075164794921875000])

Step=18: loss=-0.008378058671951294
 Input before update:  tensor([0.829096794128417968750000000000, 0.845231592655181884765625000000],
       requires_grad=True)
Input after update:  tensor([0.816497445106506347656250000000, 0.832485675811767578125000000000],
       requires_grad=True)
Gradient with respect the input:  tensor([0.125993564724922180175781250000, 0.127459168434143066406250000000])

Step=19: loss=-0.01422174833714962
 Input before update:  tensor([0.816497445106506347656250000000, 0.832485675811767578125000000000],
       requires_grad=True)
Input after update:  tensor([0.754299283027648925781250000000, 0.778157353401184082031250000000],
       requires_grad=True)
Gradient with respect the input:  tensor([0.621981620788574218750000000000, 0.543283283710479736328125000000])

Initial position: tensor([0.882269263267517089843750000000, 0.915003955364227294921875000000]); Label: tensor([1., 0.]); Radius: 0.31835806369781494/0.15915494309189535
dl Adv ex: tensor([0.426400005817413330078125000000, 0.806200027465820312500000000000]); OutLabel: tensor([0.039366275072097778320312500000, 0.990672945976257324218750000000],
       grad_fn=<TanhBackward>); Radius: 0.09917541593313217/0.15915494309189535
PyTorch Adv ex: tensor([0.754299283027648925781250000000, 0.778157353401184082031250000000],
       requires_grad=True); OutLabel: tensor([0.202751666307449340820312500000, 0.747279047966003417968750000000],
       grad_fn=<TanhBackward>); Radius: 0.14203964173793793/0.15915494309189535
