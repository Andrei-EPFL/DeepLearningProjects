Number in: 499.0, Number out: 501.0
Epoch 0: 
	Train loss: 2.60574840373478833211e-01	 Train acc: 0.49000000715255737083
	Val loss: 2.52464815107163342844e-01	 Val acc: 0.50499999523162841797
Epoch 1: 
	Train loss: 2.47577454194252477571e-01	 Train acc: 0.53600000590085983276
	Val loss: 2.41770912307502999772e-01	 Val acc: 0.52200001478195190430
Epoch 2: 
	Train loss: 2.16832780582065620667e-01	 Train acc: 0.65200000435113902864
	Val loss: 2.08572957410393083899e-01	 Val acc: 0.63099998235702514648
Epoch 3: 
	Train loss: 1.78694453196239888548e-01	 Train acc: 0.74399999916553494206
	Val loss: 1.50097662301519912953e-01	 Val acc: 0.75700002908706665039
Epoch 4: 
	Train loss: 1.40426210151976954554e-01	 Train acc: 0.80299999535083765867
	Val loss: 1.14633347246997599478e-01	 Val acc: 0.86000001430511474609
Epoch 5: 
	Train loss: 1.13037796940991516759e-01	 Train acc: 0.84699999392032621071
	Val loss: 9.17999651560452017973e-02	 Val acc: 0.88300001621246337891
Epoch 6: 
	Train loss: 9.44466812319831733324e-02	 Train acc: 0.87899999439716336447
	Val loss: 9.27885919826461347260e-02	 Val acc: 0.87199997901916503906
Epoch 7: 
	Train loss: 1.02632963056089238085e-01	 Train acc: 0.86099999547004701927
	Val loss: 7.79222142973975684388e-02	 Val acc: 0.90600001811981201172
Epoch 8: 
	Train loss: 8.76652426852767840959e-02	 Train acc: 0.88599999189376832387
	Val loss: 8.77290056865908385308e-02	 Val acc: 0.87900000810623168945
Epoch 9: 
	Train loss: 8.26154696465411508832e-02	 Train acc: 0.89399999499320981222
	Val loss: 7.31040242842982135318e-02	 Val acc: 0.91100001335144042969
Epoch 10: 
	Train loss: 8.46158216947479474568e-02	 Train acc: 0.89399999260902407450
	Val loss: 5.53241996984263767478e-02	 Val acc: 0.93500000238418579102
Epoch 11: 
	Train loss: 7.13773882798818676276e-02	 Train acc: 0.91099999129772191164
	Val loss: 7.50749244755485878322e-02	 Val acc: 0.89399999380111694336
Epoch 12: 
	Train loss: 8.16734249166303355461e-02	 Train acc: 0.89899999350309367507
	Val loss: 7.17235792729929710898e-02	 Val acc: 0.90600001811981201172
Epoch 13: 
	Train loss: 7.46378833398592816950e-02	 Train acc: 0.89899999260902407894
	Val loss: 6.50245295910029663666e-02	 Val acc: 0.91799998283386230469
Epoch 14: 
	Train loss: 6.51962518615598757288e-02	 Train acc: 0.91099999189376834607
	Val loss: 5.30269510043388583864e-02	 Val acc: 0.92699998617172241211
Epoch 15: 
	Train loss: 6.59542939807311739964e-02	 Train acc: 0.91499999165534973145
	Val loss: 6.91371024847548532044e-02	 Val acc: 0.90499997138977050781
Epoch 16: 
	Train loss: 6.18629522465219822136e-02	 Train acc: 0.91699999272823329299
	Val loss: 5.12965612436303008970e-02	 Val acc: 0.92400002479553222656
Epoch 17: 
	Train loss: 6.35989028292684305255e-02	 Train acc: 0.91799999177455904320
	Val loss: 5.82265165001214918261e-02	 Val acc: 0.92199999094009399414
Epoch 18: 
	Train loss: 5.96092482921508626248e-02	 Train acc: 0.92299999058246617878
	Val loss: 4.92775451587395968422e-02	 Val acc: 0.93400001525878906250
Epoch 19: 
	Train loss: 6.05990293885561026599e-02	 Train acc: 0.91999999403953547361
	Val loss: 7.46928642270414111515e-02	 Val acc: 0.89600002765655517578
Epoch 20: 
	Train loss: 5.90416891293664217177e-02	 Train acc: 0.92099999189376835496
	Val loss: 3.54727699199885865289e-02	 Val acc: 0.95499998331069946289
Epoch 21: 
	Train loss: 5.69938243201361383061e-02	 Train acc: 0.92499999165534974033
	Val loss: 3.83488478713981950641e-02	 Val acc: 0.95599997043609619141
Epoch 22: 
	Train loss: 5.95189813355262581362e-02	 Train acc: 0.92199999272823329743
	Val loss: 7.28241410451206522270e-02	 Val acc: 0.89800000190734863281
Epoch 23: 
	Train loss: 5.46357856683300571743e-02	 Train acc: 0.92699999094009399858
	Val loss: 3.70627221779096377441e-02	 Val acc: 0.95599997043609619141
Epoch 24: 
	Train loss: 5.24859382205761296203e-02	 Train acc: 0.92899999320507054001
	Val loss: 3.67292407419571517724e-02	 Val acc: 0.95800000429153442383
Epoch 25: 
	Train loss: 5.77647696154372156108e-02	 Train acc: 0.92499999344348904362
	Val loss: 3.84358619566352796570e-02	 Val acc: 0.95099997520446777344
Epoch 26: 
	Train loss: 4.94213762416837038005e-02	 Train acc: 0.93699999153614044189
	Val loss: 4.41632327410848152249e-02	 Val acc: 0.93699997663497924805
Epoch 27: 
	Train loss: 5.13802539629329702020e-02	 Train acc: 0.92899999141693112570
	Val loss: 4.40114987604055957204e-02	 Val acc: 0.94800001382827758789
Epoch 28: 
	Train loss: 4.61203730296662339772e-02	 Train acc: 0.94299999117851251995
	Val loss: 4.26239133167851808048e-02	 Val acc: 0.94300001859664916992
Epoch 29: 
	Train loss: 5.78314038537603297696e-02	 Train acc: 0.92899999439716340888
	Val loss: 4.42027489836340561902e-02	 Val acc: 0.94400000572204589844
Epoch 30: 
	Train loss: 5.66582667074190804435e-02	 Train acc: 0.92799999535083765867
	Val loss: 5.56739913634482982974e-02	 Val acc: 0.92199999094009399414
Epoch 31: 
	Train loss: 4.91349650731847040208e-02	 Train acc: 0.93199999332427974075
	Val loss: 4.36617721650155166113e-02	 Val acc: 0.95099997520446777344
Epoch 32: 
	Train loss: 4.24134255252446371043e-02	 Train acc: 0.94899999320507044676
	Val loss: 3.44547672956921069432e-02	 Val acc: 0.95999997854232788086
Epoch 33: 
	Train loss: 5.08246298665476006762e-02	 Train acc: 0.93699999153614044189
	Val loss: 5.11790935923394432749e-02	 Val acc: 0.93500000238418579102
Epoch 34: 
	Train loss: 4.62973779876252114485e-02	 Train acc: 0.93699999272823331076
	Val loss: 3.04575565668669182018e-02	 Val acc: 0.95599997043609619141
Epoch 35: 
	Train loss: 4.69341726289043761899e-02	 Train acc: 0.94299999237060549984
	Val loss: 4.44145740254491827592e-02	 Val acc: 0.94199997186660766602
Epoch 36: 
	Train loss: 4.70010087031476619934e-02	 Train acc: 0.94099999189376826170
	Val loss: 3.16033194500394201687e-02	 Val acc: 0.95499998331069946289
Epoch 37: 
	Train loss: 4.19153192471285254705e-02	 Train acc: 0.94499999225139619252
	Val loss: 3.01587231553460330402e-02	 Val acc: 0.96499997377395629883
Epoch 38: 
	Train loss: 4.02212306319288878664e-02	 Train acc: 0.94799999237060550428
	Val loss: 6.91790205418162662543e-02	 Val acc: 0.91399997472763061523
Epoch 39: 
	Train loss: 4.30859033788900461226e-02	 Train acc: 0.94399999320507044231
	Val loss: 4.20329409198246586876e-02	 Val acc: 0.93999999761581420898
Epoch 40: 
	Train loss: 4.43173360861897902563e-02	 Train acc: 0.93899999201297756901
	Val loss: 3.09741431847770053165e-02	 Val acc: 0.95999997854232788086
Epoch 41: 
	Train loss: 4.31370129910704433462e-02	 Train acc: 0.93999999165534975365
	Val loss: 2.71187924070310990010e-02	 Val acc: 0.96899998188018798828
Epoch 42: 
	Train loss: 4.17759122640692023842e-02	 Train acc: 0.94699999213218688521
	Val loss: 3.73815569437020780996e-02	 Val acc: 0.96299999952316284180
Epoch 43: 
	Train loss: 4.05356626995129684654e-02	 Train acc: 0.94299999177455906541
	Val loss: 3.56133881803111784770e-02	 Val acc: 0.95300000905990600586
Epoch 44: 
	Train loss: 3.72506370751070278735e-02	 Train acc: 0.95499999225139620140
	Val loss: 3.27958172433557015868e-02	 Val acc: 0.95800000429153442383
Epoch 45: 
	Train loss: 3.74165601426572000388e-02	 Train acc: 0.95299999356269837758
	Val loss: 3.44978964640232158012e-02	 Val acc: 0.95300000905990600586
Epoch 46: 
	Train loss: 3.74689009949134704813e-02	 Train acc: 0.94899999320507044676
	Val loss: 4.40240024468385379719e-02	 Val acc: 0.94400000572204589844
Epoch 47: 
	Train loss: 4.12304760683800120002e-02	 Train acc: 0.93999999225139618808
	Val loss: 3.18618403085427492893e-02	 Val acc: 0.96100002527236938477
Epoch 48: 
	Train loss: 3.39234033807460921839e-02	 Train acc: 0.95399999380111699665
	Val loss: 3.51598564245720821009e-02	 Val acc: 0.95399999618530273438
Epoch 49: 
	Train loss: 3.52953700120113289529e-02	 Train acc: 0.95199999332427975851
	Val loss: 2.89888009885610198335e-02	 Val acc: 0.96700000762939453125

==> End of training after 3.7417311668395996 seconds. Generating a new test set

Final test loss: 0.024	Final test acc: 0.97	Final test error 0.03

Step=0: loss=0.001802950628138169
 Input before update:  tensor([0.882269263267517089843750000000, 0.915003955364227294921875000000])
Input after update:  tensor([0.884033319343567991488441748515, 0.917473665541025718006551414874])
Gradient with respect the input:  tensor([0.017640560760509113591432139856, 0.024697101767984362685748322974])

Step=1: loss=0.0018962406685275365
 Input before update:  tensor([0.884033319343567991488441748515, 0.917473665541025718006551414874])
Input after update:  tensor([0.885842461537228231804874667432, 0.920006404023051893581452986837])
Gradient with respect the input:  tensor([0.018091421936602344183731005955, 0.025327384820261273495889398077])

Step=2: loss=0.0019943528817452654
 Input before update:  tensor([0.885842461537228231804874667432, 0.920006404023051893581452986837])
Input after update:  tensor([0.887697735012934363574288454402, 0.922603651498170584943636640674])
Gradient with respect the input:  tensor([0.018552734757060995035571338008, 0.025972474751186382796452889465])

Step=3: loss=0.002097526104913343
 Input before update:  tensor([0.887697735012934363574288454402, 0.922603651498170584943636640674])
Input after update:  tensor([0.889600220028820554141191223607, 0.925266934405023833143388856115])
Gradient with respect the input:  tensor([0.019024850158862040977458818247, 0.026632829068532665878210607957])

Step=4: loss=0.002206011680492403
 Input before update:  tensor([0.889600220028820554141191223607, 0.925266934405023833143388856115])
Input after update:  tensor([0.891551030476520067757917331619, 0.927997823453093451107065448014])
Gradient with respect the input:  tensor([0.019508104476994716364179893731, 0.027308890480696589031506249512])

Step=5: loss=0.0023200739047689175
 Input before update:  tensor([0.891551030476520067757917331619, 0.927997823453093451107065448014])
Input after update:  tensor([0.893551312640908590445576464845, 0.930797932373787384463525995670])
Gradient with respect the input:  tensor([0.020002821643885657088013374505, 0.028001089206939052539402368325])

Step=6: loss=0.0024399905026355915
 Input before update:  tensor([0.893551312640908590445576464845, 0.930797932373787384463525995670])
Input after update:  tensor([0.895602244158431703979772464663, 0.933668916879513033357795848133])
Gradient with respect the input:  tensor([0.020509315175231610656192415831, 0.028709845057256263428646647640])

Step=7: loss=0.0025660531290978925
 Input before update:  tensor([0.895602244158431703979772464663, 0.933668916879513033357795848133])
Input after update:  tensor([0.897705033151559028681276686257, 0.936612473806312517687899799057])
Gradient with respect the input:  tensor([0.021027889931272740475787230707, 0.029435569267995242287438983908])

Step=8: loss=0.0026985678976306463
 Input before update:  tensor([0.897705033151559028681276686257, 0.936612473806312517687899799057])
Input after update:  tensor([0.899860917516531189086492759088, 0.939630340415040343771124753403])
Gradient with respect the input:  tensor([0.021558843649721083635117935273, 0.030178666087278527979664843883])

Step=9: loss=0.0028378559352346257
 Input before update:  tensor([0.899860917516531189086492759088, 0.939630340415040343771124753403])
Input after update:  tensor([0.902071164341754827553643281135, 0.942724293826101789051108426065])
Gradient with respect the input:  tensor([0.022102468252236801005139454901, 0.030939534110614261980254369178])

Step=10: loss=0.0029842539637989058
 Input before update:  tensor([0.902071164341754827553643281135, 0.942724293826101789051108426065])
Input after update:  tensor([0.904337069434824392111238466896, 0.945896150563294790813984036504])
Gradient with respect the input:  tensor([0.022659050930695541492543299000, 0.031718567371930010689862200479])

Step=11: loss=0.0031381149071547662
 Input before update:  tensor([0.904337069434824392111238466896, 0.945896150563294790813984036504])
Input after update:  tensor([0.906659956937092004203293527098, 0.949147766183180197074875650287])
Gradient with respect the input:  tensor([0.023228875022676294392898199703, 0.032516156198854374859141813658])

Step=12: loss=0.003299808523005948
 Input before update:  tensor([0.906659956937092004203293527098, 0.949147766183180197074875650287])
Input after update:  tensor([0.909041179005869448559451484471, 0.952481034967534778701292452752])
Gradient with respect the input:  tensor([0.023812220687774096616884378363, 0.033332687843545573402881387892])

Step=13: loss=0.0034697220587331266
 Input before update:  tensor([0.909041179005869448559451484471, 0.952481034967534778701292452752])
Input after update:  tensor([0.911482115545634741238245624118, 0.955897889657723487388807370735])
Gradient with respect the input:  tensor([0.024409365397653235568720120341, 0.034168546901887530964359029895])

Step=14: loss=0.0036482609298913275
 Input before update:  tensor([0.911482115545634741238245624118, 0.955897889657723487388807370735])
Input after update:  tensor([0.913984173970968316602636605239, 0.959400301211182249261355536873])
Gradient with respect the input:  tensor([0.025020584253335736296675051449, 0.035024115534587563214330430128])

Step=15: loss=0.003835849420043288
 Input before update:  tensor([0.913984173970968316602636605239, 0.959400301211182249261355536873])
Input after update:  tensor([0.916548788985288687136687713064, 0.962990278561558055159252944577])
Gradient with respect the input:  tensor([0.025646150143203250842960372324, 0.035899773503758607151592485707])

Step=16: loss=0.00403293140039309
 Input before update:  tensor([0.916548788985288687136687713064, 0.962990278561558055159252944577])
Input after update:  tensor([0.919177422360758056285590100742, 0.966669868365366391493864739459])
Gradient with respect the input:  tensor([0.026286333754693445158290288077, 0.036795898038083169057088639420])

Step=17: loss=0.004239971067498466
 Input before update:  tensor([0.919177422360758056285590100742, 0.966669868365366391493864739459])
Input after update:  tensor([0.921871562705939284754208529193, 0.970441154719242748960539302061])
Gradient with respect the input:  tensor([0.026941403451812624691985575964, 0.037712863538763602422321241647])

Step=18: loss=0.004457453697141725
 Input before update:  tensor([0.921871562705939284754208529193, 0.970441154719242748960539302061])
Input after update:  tensor([0.924632725208885952739024105540, 0.974306258832970173422438620037])
Gradient with respect the input:  tensor([0.027611625029466190656135538006, 0.038651041137274327885720026643])

Step=19: loss=0.004685886412222967
 Input before update:  tensor([0.924632725208885952739024105540, 0.974306258832970173422438620037])
Input after update:  tensor([0.927462451344317706514175370103, 0.978267338644425055171893745865])
Gradient with respect the input:  tensor([0.028297261354317138765113170962, 0.039610798114548817494551258278])

Initial position: tensor([0.882269263267517089843750000000, 0.915003955364227294921875000000]); Label: tensor([1., 0.]); Radius: 0.31835807260704385/0.15915494309189535
dl Adv ex: tensor([0.927462451344317706514175370103, 0.978267338644425055171893745865]); OutLabel: tensor([ 0.999975543886582496355686089373, -0.099255213094846347909872008586]); Radius: 0.41146379452331433/0.15915494309189535
PyTorch Adv ex: tensor([0.426400000000000001243449787580, 0.806200000000000027711166694644]); OutLabel: tensor([0.038705943140540946534322586103, 0.984584120524213179947992102825]); Radius: 0.09917540000000001/0.15915494309189535
