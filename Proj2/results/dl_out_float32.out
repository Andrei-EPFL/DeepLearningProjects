Number in: 499.0, Number out: 501.0
Epoch 0: 
	Train loss: 2.60401631593704219192e-01	 Train acc: 0.48500000715255736639
	Val loss: 2.52878546714782714844e-01	 Val acc: 0.50499999523162841797
Epoch 1: 
	Train loss: 2.52489285618066772177e-01	 Train acc: 0.50900000624358654466
	Val loss: 2.48112425208091735840e-01	 Val acc: 0.50499999523162841797
Epoch 2: 
	Train loss: 2.43818717300891885102e-01	 Train acc: 0.56700000673532491291
	Val loss: 2.19080135226249694824e-01	 Val acc: 0.56699997186660766602
Epoch 3: 
	Train loss: 2.08907755091786384583e-01	 Train acc: 0.67800000585615638471
	Val loss: 1.52483269572257995605e-01	 Val acc: 0.78799998760223388672
Epoch 4: 
	Train loss: 1.81440490819513799980e-01	 Train acc: 0.74899999886751178479
	Val loss: 1.26379758119583129883e-01	 Val acc: 0.83899998664855957031
Epoch 5: 
	Train loss: 1.44949338026344770602e-01	 Train acc: 0.79699999630451201504
	Val loss: 8.94680395722389221191e-02	 Val acc: 0.91399997472763061523
Epoch 6: 
	Train loss: 1.35927449055016053014e-01	 Train acc: 0.82099999636411669091
	Val loss: 8.00622329115867614746e-02	 Val acc: 0.91500002145767211914
Epoch 7: 
	Train loss: 1.07162552345544101473e-01	 Train acc: 0.84999999523162839132
	Val loss: 6.46371990442276000977e-02	 Val acc: 0.96499997377395629883
Epoch 8: 
	Train loss: 9.23480464052408994702e-02	 Train acc: 0.88199999392032624179
	Val loss: 5.49619682133197784424e-02	 Val acc: 0.93699997663497924805
Epoch 9: 
	Train loss: 9.58961051609367176596e-02	 Train acc: 0.87599999666213990146
	Val loss: 7.68420174717903137207e-02	 Val acc: 0.89800000190734863281
Epoch 10: 
	Train loss: 8.81466711545363101887e-02	 Train acc: 0.89099999308586119717
	Val loss: 7.99860060214996337891e-02	 Val acc: 0.87999999523162841797
Epoch 11: 
	Train loss: 7.82444211118854537901e-02	 Train acc: 0.89599999368190763605
	Val loss: 6.84009939432144165039e-02	 Val acc: 0.91399997472763061523
Epoch 12: 
	Train loss: 7.80062180012464495560e-02	 Train acc: 0.90299999296665189874
	Val loss: 8.36558640003204345703e-02	 Val acc: 0.89300000667572021484
Epoch 13: 
	Train loss: 8.40416696807369523192e-02	 Train acc: 0.88899999499320980778
	Val loss: 9.74086076021194458008e-02	 Val acc: 0.86900001764297485352
Epoch 14: 
	Train loss: 7.00307104922830991889e-02	 Train acc: 0.91299999415874477648
	Val loss: 5.04212640225887298584e-02	 Val acc: 0.94099998474121093750
Epoch 15: 
	Train loss: 7.26963254250586055072e-02	 Train acc: 0.90199999332427982512
	Val loss: 6.08100779354572296143e-02	 Val acc: 0.91399997472763061523
Epoch 16: 
	Train loss: 7.19479749561287434956e-02	 Train acc: 0.91099999189376834607
	Val loss: 4.62503954768180847168e-02	 Val acc: 0.94900000095367431641
Epoch 17: 
	Train loss: 7.55294474354013811723e-02	 Train acc: 0.89799999296665189430
	Val loss: 5.90909756720066070557e-02	 Val acc: 0.91799998283386230469
Epoch 18: 
	Train loss: 7.06853282637894125839e-02	 Train acc: 0.91199999213218685412
	Val loss: 4.11086827516555786133e-02	 Val acc: 0.94999998807907104492
Epoch 19: 
	Train loss: 6.09794108429923681358e-02	 Train acc: 0.92299999296665191650
	Val loss: 4.39916290342807769775e-02	 Val acc: 0.94900000095367431641
Epoch 20: 
	Train loss: 6.36356107145547855719e-02	 Train acc: 0.91699999392032627288
	Val loss: 4.73402999341487884521e-02	 Val acc: 0.93500000238418579102
Epoch 21: 
	Train loss: 6.27198914811015195703e-02	 Train acc: 0.92099999248981478939
	Val loss: 3.72530333697795867920e-02	 Val acc: 0.95700001716613769531
Epoch 22: 
	Train loss: 5.53204432385973610131e-02	 Train acc: 0.92699999213218686744
	Val loss: 5.33345714211463928223e-02	 Val acc: 0.93000000715255737305
Epoch 23: 
	Train loss: 5.99658509204164177908e-02	 Train acc: 0.91799999177455904320
	Val loss: 9.76569801568984985352e-02	 Val acc: 0.85199999809265136719
Epoch 24: 
	Train loss: 5.89304259256459780913e-02	 Train acc: 0.91599999248981478495
	Val loss: 5.47001957893371582031e-02	 Val acc: 0.92699998617172241211
Epoch 25: 
	Train loss: 5.28537274501286458150e-02	 Train acc: 0.93399999499320984775
	Val loss: 4.74794991314411163330e-02	 Val acc: 0.93900001049041748047
Epoch 26: 
	Train loss: 5.10560367477592078056e-02	 Train acc: 0.93699999213218687633
	Val loss: 5.80353289842605590820e-02	 Val acc: 0.92299997806549072266
Epoch 27: 
	Train loss: 5.19337392889428900444e-02	 Train acc: 0.93399999260902399900
	Val loss: 8.59147906303405761719e-02	 Val acc: 0.88300001621246337891
Epoch 28: 
	Train loss: 5.42994868956157006323e-02	 Train acc: 0.92999999582767489681
	Val loss: 8.94823372364044189453e-02	 Val acc: 0.88200002908706665039
Epoch 29: 
	Train loss: 6.06743384897708917802e-02	 Train acc: 0.92499999284744260919
	Val loss: 4.76009398698806762695e-02	 Val acc: 0.93500000238418579102
Epoch 30: 
	Train loss: 5.08248207566793994139e-02	 Train acc: 0.93599999070167538839
	Val loss: 5.43211065232753753662e-02	 Val acc: 0.92400002479553222656
Epoch 31: 
	Train loss: 4.83618493378162386809e-02	 Train acc: 0.93799999356269836426
	Val loss: 5.77257573604583740234e-02	 Val acc: 0.92000001668930053711
Epoch 32: 
	Train loss: 5.29226325417403165030e-02	 Train acc: 0.93099999308586123270
	Val loss: 4.93180938065052032471e-02	 Val acc: 0.93599998950958251953
Epoch 33: 
	Train loss: 5.04175595112610619442e-02	 Train acc: 0.93399999380111697889
	Val loss: 4.08783219754695892334e-02	 Val acc: 0.94099998474121093750
Epoch 34: 
	Train loss: 4.61740497464779783843e-02	 Train acc: 0.94099999427795411044
	Val loss: 3.43367159366607666016e-02	 Val acc: 0.95300000905990600586
Epoch 35: 
	Train loss: 4.92852959758602049423e-02	 Train acc: 0.93199999332427974075
	Val loss: 5.47539889812469482422e-02	 Val acc: 0.93599998950958251953
Epoch 36: 
	Train loss: 4.46459076966857562607e-02	 Train acc: 0.94299999356269836870
	Val loss: 2.91027482599020004272e-02	 Val acc: 0.96399998664855957031
Epoch 37: 
	Train loss: 4.55794126051478065698e-02	 Train acc: 0.94099999308586124158
	Val loss: 3.60620878636837005615e-02	 Val acc: 0.94800001382827758789
Epoch 38: 
	Train loss: 4.23288485303055517228e-02	 Train acc: 0.94599999308586124602
	Val loss: 3.28251123428344726562e-02	 Val acc: 0.95899999141693115234
Epoch 39: 
	Train loss: 4.19324991846224265357e-02	 Train acc: 0.94299999356269836870
	Val loss: 4.05095592141151428223e-02	 Val acc: 0.94499999284744262695
Epoch 40: 
	Train loss: 4.38908174895914285352e-02	 Train acc: 0.94199999392032618406
	Val loss: 6.18527010083198547363e-02	 Val acc: 0.91699999570846557617
Epoch 41: 
	Train loss: 4.99116734939161685314e-02	 Train acc: 0.94199999451637272951
	Val loss: 3.43092307448387145996e-02	 Val acc: 0.96100002527236938477
Epoch 42: 
	Train loss: 4.47846086812205626537e-02	 Train acc: 0.94199999511241916395
	Val loss: 3.53306308388710021973e-02	 Val acc: 0.95700001716613769531
Epoch 43: 
	Train loss: 4.71792128001106911284e-02	 Train acc: 0.93799999296665192983
	Val loss: 5.91191239655017852783e-02	 Val acc: 0.91699999570846557617
Epoch 44: 
	Train loss: 4.61412629086407830026e-02	 Train acc: 0.93999999225139618808
	Val loss: 5.74101284146308898926e-02	 Val acc: 0.93000000715255737305
Epoch 45: 
	Train loss: 4.42013717087684221418e-02	 Train acc: 0.94199999451637272951
	Val loss: 3.68305779993534088135e-02	 Val acc: 0.95399999618530273438
Epoch 46: 
	Train loss: 4.11738090260769240558e-02	 Train acc: 0.95199999392032619294
	Val loss: 5.19286729395389556885e-02	 Val acc: 0.92699998617172241211
Epoch 47: 
	Train loss: 4.55518449150258686320e-02	 Train acc: 0.94499999344348906138
	Val loss: 2.76536606252193450928e-02	 Val acc: 0.96399998664855957031
Epoch 48: 
	Train loss: 5.08507066898164356017e-02	 Train acc: 0.92999999582767489681
	Val loss: 3.77103649079799652100e-02	 Val acc: 0.96100002527236938477
Epoch 49: 
	Train loss: 4.26490051276050483042e-02	 Train acc: 0.94499999344348906138
	Val loss: 4.26728352904319763184e-02	 Val acc: 0.93900001049041748047

==> End of training after 3.7707815170288086 seconds. Generating a new test set

Final test loss: 0.040	Final test acc: 0.95	Final test error 0.05

Step=0: loss=0.0008696997538208961
 Input before update:  tensor([0.882269263267517089843750000000, 0.915003955364227294921875000000])
Input after update:  tensor([0.881471455097198486328125000000, 0.913763403892517089843750000000])
Gradient with respect the input:  tensor([-0.007978132925927639007568359375, -0.012405703775584697723388671875])

Step=1: loss=0.0008916019578464329
 Input before update:  tensor([0.881471455097198486328125000000, 0.913763403892517089843750000000])
Input after update:  tensor([0.880662620067596435546875000000, 0.912506282329559326171875000000])
Gradient with respect the input:  tensor([-0.008088279515504837036132812500, -0.012571318075060844421386718750])

Step=2: loss=0.0009140983456745744
 Input before update:  tensor([0.880662620067596435546875000000, 0.912506282329559326171875000000])
Input after update:  tensor([0.879842460155487060546875000000, 0.911232233047485351562500000000])
Gradient with respect the input:  tensor([-0.008201411925256252288818359375, -0.012740748003125190734863281250])

Step=3: loss=0.0009372156928293407
 Input before update:  tensor([0.879842460155487060546875000000, 0.911232233047485351562500000000])
Input after update:  tensor([0.879010677337646484375000000000, 0.909940779209136962890625000000])
Gradient with respect the input:  tensor([-0.008317820727825164794921875000, -0.012914328835904598236083984375])

Step=4: loss=0.0009609769913367927
 Input before update:  tensor([0.879010677337646484375000000000, 0.909940779209136962890625000000])
Input after update:  tensor([0.878166913986206054687500000000, 0.908631563186645507812500000000])
Gradient with respect the input:  tensor([-0.008437814190983772277832031250, -0.013092403300106525421142578125])

Step=5: loss=0.0009854098316282034
 Input before update:  tensor([0.878166913986206054687500000000, 0.908631563186645507812500000000])
Input after update:  tensor([0.877310752868652343750000000000, 0.907304048538208007812500000000])
Gradient with respect the input:  tensor([-0.008561779744923114776611328125, -0.013275399804115295410156250000])

Step=6: loss=0.0010105426190420985
 Input before update:  tensor([0.877310752868652343750000000000, 0.907304048538208007812500000000])
Input after update:  tensor([0.876441717147827148437500000000, 0.905957698822021484375000000000])
Gradient with respect the input:  tensor([-0.008690135553479194641113281250, -0.013463783077895641326904296875])

Step=7: loss=0.0010364094050601125
 Input before update:  tensor([0.876441717147827148437500000000, 0.905957698822021484375000000000])
Input after update:  tensor([0.875559389591217041015625000000, 0.904591858386993408203125000000])
Gradient with respect the input:  tensor([-0.008823404088616371154785156250, -0.013658133335411548614501953125])

Step=8: loss=0.0010630472097545862
 Input before update:  tensor([0.875559389591217041015625000000, 0.904591858386993408203125000000])
Input after update:  tensor([0.874663174152374267578125000000, 0.903205931186676025390625000000])
Gradient with respect the input:  tensor([-0.008962181396782398223876953125, -0.013859115540981292724609375000])

Step=9: loss=0.0010904965456575155
 Input before update:  tensor([0.874663174152374267578125000000, 0.903205931186676025390625000000])
Input after update:  tensor([0.873752474784851074218750000000, 0.901799201965332031250000000000])
Gradient with respect the input:  tensor([-0.009107170626521110534667968750, -0.014067496173083782196044921875])

Step=10: loss=0.00111879943870008
 Input before update:  tensor([0.873752474784851074218750000000, 0.901799201965332031250000000000])
Input after update:  tensor([0.872826576232910156250000000000, 0.900370776653289794921875000000])
Gradient with respect the input:  tensor([-0.009259173646569252014160156250, -0.014284163713455200195312500000])

Step=11: loss=0.0011485297000035644
 Input before update:  tensor([0.872826576232910156250000000000, 0.900370776653289794921875000000])
Input after update:  tensor([0.871841609477996826171875000000, 0.898882269859313964843750000000])
Gradient with respect the input:  tensor([-0.009849460795521736145019531250, -0.014884945005178451538085937500])

Step=12: loss=0.0011806454276666045
 Input before update:  tensor([0.871841609477996826171875000000, 0.898882269859313964843750000000])
Input after update:  tensor([0.870838820934295654296875000000, 0.897370159626007080078125000000])
Gradient with respect the input:  tensor([-0.010027739219367504119873046875, -0.015120899304747581481933593750])

Step=13: loss=0.0012138657039031386
 Input before update:  tensor([0.870838820934295654296875000000, 0.897370159626007080078125000000])
Input after update:  tensor([0.869816303253173828125000000000, 0.895831048488616943359375000000])
Gradient with respect the input:  tensor([-0.010225049220025539398193359375, -0.015390820801258087158203125000])

Step=14: loss=0.0012483360478654504
 Input before update:  tensor([0.869816303253173828125000000000, 0.895831048488616943359375000000])
Input after update:  tensor([0.868772685527801513671875000000, 0.894263386726379394531250000000])
Gradient with respect the input:  tensor([-0.010436243377625942230224609375, -0.015676621347665786743164062500])

Step=15: loss=0.0012841566931456327
 Input before update:  tensor([0.868772685527801513671875000000, 0.894263386726379394531250000000])
Input after update:  tensor([0.867706298828125000000000000000, 0.892665326595306396484375000000])
Gradient with respect the input:  tensor([-0.010663706809282302856445312500, -0.015980897471308708190917968750])

Step=16: loss=0.0013214553473517299
 Input before update:  tensor([0.867706298828125000000000000000, 0.892665326595306396484375000000])
Input after update:  tensor([0.866615235805511474609375000000, 0.891034662723541259765625000000])
Gradient with respect the input:  tensor([-0.010910402052104473114013671875, -0.016306893900036811828613281250])

Step=17: loss=0.0013603806728497148
 Input before update:  tensor([0.866615235805511474609375000000, 0.891034662723541259765625000000])
Input after update:  tensor([0.865497231483459472656250000000, 0.889368832111358642578125000000])
Gradient with respect the input:  tensor([-0.011179982684552669525146484375, -0.016658591106534004211425781250])

Step=18: loss=0.001401108456775546
 Input before update:  tensor([0.865497231483459472656250000000, 0.889368832111358642578125000000])
Input after update:  tensor([0.864349544048309326171875000000, 0.887664735317230224609375000000])
Gradient with respect the input:  tensor([-0.011476961895823478698730468750, -0.017040908336639404296875000000])

Step=19: loss=0.001443858491256833
 Input before update:  tensor([0.864349544048309326171875000000, 0.887664735317230224609375000000])
Input after update:  tensor([0.863168835639953613281250000000, 0.885918736457824707031250000000])
Gradient with respect the input:  tensor([-0.011807108297944068908691406250, -0.017460120841860771179199218750])

Initial position: tensor([0.882269263267517089843750000000, 0.915003955364227294921875000000]); Label: tensor([1., 0.]); Radius: 0.31835806369781494/0.15915494309189535
dl Adv ex: tensor([0.863168835639953613281250000000, 0.885918736457824707031250000000]); OutLabel: tensor([0.992359042167663574218750000000, 0.054031595587730407714843750000]); Radius: 0.2808248996734619/0.15915494309189535
PyTorch Adv ex: tensor([0.426400005817413330078125000000, 0.806200027465820312500000000000]); OutLabel: tensor([-0.059826400130987167358398437500,  0.985479831695556640625000000000]); Radius: 0.09917541593313217/0.15915494309189535
