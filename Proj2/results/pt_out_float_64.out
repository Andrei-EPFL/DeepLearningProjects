Number in: 499.0, Number out: 501.0
Epoch 0: 
	Train loss: 2.60574840373478888722e-01	 Train acc: 0.49000000715255737083
	Val loss: 2.52464815107163342844e-01	 Val acc: 0.50499999523162841797
Epoch 1: 
	Train loss: 2.47577454194252477571e-01	 Train acc: 0.53600000590085983276
	Val loss: 2.41770912307503027527e-01	 Val acc: 0.52200001478195190430
Epoch 2: 
	Train loss: 2.16832780582065620667e-01	 Train acc: 0.65200000435113902864
	Val loss: 2.08572957410393222677e-01	 Val acc: 0.63099998235702514648
Epoch 3: 
	Train loss: 1.78694453196239999571e-01	 Train acc: 0.74399999916553494206
	Val loss: 1.50097662301519940709e-01	 Val acc: 0.75700002908706665039
Epoch 4: 
	Train loss: 1.40426210151976982310e-01	 Train acc: 0.80299999535083765867
	Val loss: 1.14633347246997613356e-01	 Val acc: 0.86000001430511474609
Epoch 5: 
	Train loss: 1.13037796940991502881e-01	 Train acc: 0.84699999392032621071
	Val loss: 9.17999651560451185306e-02	 Val acc: 0.88300001621246337891
Epoch 6: 
	Train loss: 9.44466812319832149658e-02	 Train acc: 0.87899999439716336447
	Val loss: 9.27885919826460930926e-02	 Val acc: 0.87199997901916503906
Epoch 7: 
	Train loss: 1.02632963056089251963e-01	 Train acc: 0.86099999547004701927
	Val loss: 7.79222142973979015057e-02	 Val acc: 0.90600001811981201172
Epoch 8: 
	Train loss: 8.76652426852768396071e-02	 Train acc: 0.88599999189376832387
	Val loss: 8.77290056865908940420e-02	 Val acc: 0.87900000810623168945
Epoch 9: 
	Train loss: 8.26154696465410537387e-02	 Train acc: 0.89399999499320981222
	Val loss: 7.31040242842982829208e-02	 Val acc: 0.91100001335144042969
Epoch 10: 
	Train loss: 8.46158216947478086789e-02	 Train acc: 0.89399999260902407450
	Val loss: 5.53241996984265849147e-02	 Val acc: 0.93500000238418579102
Epoch 11: 
	Train loss: 7.13773882798812292494e-02	 Train acc: 0.91099999129772191164
	Val loss: 7.50749244755478106761e-02	 Val acc: 0.89399999380111694336
Epoch 12: 
	Train loss: 8.16734249166341519377e-02	 Train acc: 0.89899999350309367507
	Val loss: 7.17235792729939980461e-02	 Val acc: 0.90600001811981201172
Epoch 13: 
	Train loss: 7.46378833398549379474e-02	 Train acc: 0.89899999260902407894
	Val loss: 6.50245295910025777886e-02	 Val acc: 0.91799998283386230469
Epoch 14: 
	Train loss: 6.51962518615591124505e-02	 Train acc: 0.91099999189376834607
	Val loss: 5.30269510043402045318e-02	 Val acc: 0.92699998617172241211
Epoch 15: 
	Train loss: 6.59542939807360312221e-02	 Train acc: 0.91499999165534973145
	Val loss: 6.91371024847193677010e-02	 Val acc: 0.90499997138977050781
Epoch 16: 
	Train loss: 6.18629522465186376667e-02	 Train acc: 0.91699999272823329299
	Val loss: 5.12965612436342421887e-02	 Val acc: 0.92400002479553222656
Epoch 17: 
	Train loss: 6.35989028292724550839e-02	 Train acc: 0.91799999177455904320
	Val loss: 5.82265165002376489101e-02	 Val acc: 0.92199999094009399414
Epoch 18: 
	Train loss: 5.96092482922017663505e-02	 Train acc: 0.92299999058246617878
	Val loss: 4.92775451585745621896e-02	 Val acc: 0.93400001525878906250
Epoch 19: 
	Train loss: 6.05990293885547148811e-02	 Train acc: 0.91999999403953547361
	Val loss: 7.46928642371163936664e-02	 Val acc: 0.89600002765655517578
Epoch 20: 
	Train loss: 5.90416891283647229938e-02	 Train acc: 0.92099999189376835496
	Val loss: 3.54727699191175957494e-02	 Val acc: 0.95499998331069946289
Epoch 21: 
	Train loss: 5.69938243219838477915e-02	 Train acc: 0.92499999165534974033
	Val loss: 3.83488478639133975601e-02	 Val acc: 0.95599997043609619141
Epoch 22: 
	Train loss: 5.95189813253833924223e-02	 Train acc: 0.92199999272823329743
	Val loss: 7.28241410526484361787e-02	 Val acc: 0.89800000190734863281
Epoch 23: 
	Train loss: 5.46357856720508586190e-02	 Train acc: 0.92699999094009399858
	Val loss: 3.70627221672209933301e-02	 Val acc: 0.95599997043609619141
Epoch 24: 
	Train loss: 5.24859381311622089084e-02	 Train acc: 0.92899999320507054001
	Val loss: 3.67292408486040652948e-02	 Val acc: 0.95800000429153442383
Epoch 25: 
	Train loss: 5.77647722019284243222e-02	 Train acc: 0.92499999344348904362
	Val loss: 3.84358823905209881500e-02	 Val acc: 0.95099997520446777344
Epoch 26: 
	Train loss: 4.94213725485163138385e-02	 Train acc: 0.93699999153614044189
	Val loss: 4.41632234137088255932e-02	 Val acc: 0.93699997663497924805
Epoch 27: 
	Train loss: 5.13801957829503330721e-02	 Train acc: 0.92899999141693112570
	Val loss: 4.40116469017250572238e-02	 Val acc: 0.94800001382827758789
Epoch 28: 
	Train loss: 4.61201366173045468333e-02	 Train acc: 0.94299999117851251995
	Val loss: 4.26231878514552117720e-02	 Val acc: 0.94300001859664916992
Epoch 29: 
	Train loss: 5.12534951068562977250e-02	 Train acc: 0.93899999141693113458
	Val loss: 3.22318631826896614956e-02	 Val acc: 0.95899999141693115234
Epoch 30: 
	Train loss: 4.74619768279316497916e-02	 Train acc: 0.93799999177455906096
	Val loss: 1.33510913689100452206e-01	 Val acc: 0.83099997043609619141
Epoch 31: 
	Train loss: 4.75320396073563231076e-02	 Train acc: 0.94499999225139619252
	Val loss: 4.20097250033209176912e-02	 Val acc: 0.94300001859664916992
Epoch 32: 
	Train loss: 5.27094151830430415751e-02	 Train acc: 0.93399999082088469571
	Val loss: 3.62093611913266305580e-02	 Val acc: 0.95200002193450927734
Epoch 33: 
	Train loss: 4.11794326267410845666e-02	 Train acc: 0.95099999248981470501
	Val loss: 3.72313966692453673923e-02	 Val acc: 0.94900000095367431641
Epoch 34: 
	Train loss: 4.43838639044931426714e-02	 Train acc: 0.93699999153614044189
	Val loss: 4.03130099002211791936e-02	 Val acc: 0.94499999284744262695
Epoch 35: 
	Train loss: 4.52884243874750319625e-02	 Train acc: 0.94199999213218688077
	Val loss: 3.17772747105867572892e-02	 Val acc: 0.95700001716613769531
Epoch 36: 
	Train loss: 4.54906858704346578337e-02	 Train acc: 0.93099999010562894952
	Val loss: 7.78222880371604031069e-02	 Val acc: 0.89300000667572021484
Epoch 37: 
	Train loss: 4.12102006438586423998e-02	 Train acc: 0.95099999189376827058
	Val loss: 4.78834243603119200094e-02	 Val acc: 0.93300002813339233398
Epoch 38: 
	Train loss: 4.51053408703403838076e-02	 Train acc: 0.94099999308586124158
	Val loss: 4.81380295721409168230e-02	 Val acc: 0.93599998950958251953
Epoch 39: 
	Train loss: 4.91756240077983880488e-02	 Train acc: 0.93099999189376836384
	Val loss: 3.93775137481952586249e-02	 Val acc: 0.94599997997283935547
Epoch 40: 
	Train loss: 4.28098038455086982168e-02	 Train acc: 0.93699999094009400746
	Val loss: 3.96023313163364476530e-02	 Val acc: 0.94900000095367431641
Epoch 41: 
	Train loss: 3.83707418218982992952e-02	 Train acc: 0.94999999344348906583
	Val loss: 3.65782593198093058939e-02	 Val acc: 0.95099997520446777344
Epoch 42: 
	Train loss: 4.58312275736905486156e-02	 Train acc: 0.93599999248981480271
	Val loss: 3.15472754440220271022e-02	 Val acc: 0.96200001239776611328
Epoch 43: 
	Train loss: 3.75113576427807404734e-02	 Train acc: 0.94799999177455906985
	Val loss: 3.24050441607413239331e-02	 Val acc: 0.96299999952316284180
Epoch 44: 
	Train loss: 3.87610621923072107275e-02	 Train acc: 0.94299999356269836870
	Val loss: 2.98331643335579162202e-02	 Val acc: 0.96899998188018798828
Epoch 45: 
	Train loss: 3.76883331633381529757e-02	 Train acc: 0.95399999201297758233
	Val loss: 2.78364795468047168669e-02	 Val acc: 0.96700000762939453125
Epoch 46: 
	Train loss: 3.94144981248538139873e-02	 Train acc: 0.95499999463558193913
	Val loss: 2.88516158782063485144e-02	 Val acc: 0.95999997854232788086
Epoch 47: 
	Train loss: 3.73542452265595084637e-02	 Train acc: 0.95199999272823332408
	Val loss: 3.39011774394791590148e-02	 Val acc: 0.95700001716613769531
Epoch 48: 
	Train loss: 4.09669102812891539056e-02	 Train acc: 0.94899999141693114346
	Val loss: 3.21919434163791609582e-02	 Val acc: 0.96200001239776611328
Epoch 49: 
	Train loss: 3.90140842962831760343e-02	 Train acc: 0.94299999356269836870
	Val loss: 3.21231948452781052028e-02	 Val acc: 0.95800000429153442383

==> End of training after 3.7097890377044678 seconds. Generating a new test set

Final test loss: 0.028	Final test acc: 0.96	Final test error 0.04

Step=0: loss=-6.11139703938255e-05
 Input before update:  tensor([0.882269263267517089843750000000, 0.915003955364227294921875000000],
       requires_grad=True)
Input after update:  tensor([0.882529385312148861864045557013, 0.915450912411810646673870905943],
       requires_grad=True)
Gradient with respect the input:  tensor([-0.002601220446318198119273201740, -0.004469570475833413436550500819])

Step=1: loss=-6.38183815810701e-05
 Input before update:  tensor([0.882529385312148861864045557013, 0.915450912411810646673870905943],
       requires_grad=True)
Input after update:  tensor([0.882795376664475162087342141604, 0.915907908076155852228339426802],
       requires_grad=True)
Gradient with respect the input:  tensor([-0.002659913523262669166058458359, -0.004569956643452268915672753735])

Step=2: loss=-6.664576799647216e-05
 Input before update:  tensor([0.882795376664475162087342141604, 0.915907908076155852228339426802],
       requires_grad=True)
Input after update:  tensor([0.883067365686454164297458646615, 0.916375163266889281032945291372],
       requires_grad=True)
Gradient with respect the input:  tensor([-0.002719890219790131388744036656, -0.004672551907334314934272523345])

Step=3: loss=-6.960165647867101e-05
 Input before update:  tensor([0.883067365686454164297458646615, 0.916375163266889281032945291372],
       requires_grad=True)
Input after update:  tensor([0.883345483553823584976782967715, 0.916852903735131175011474624625],
       requires_grad=True)
Gradient with respect the input:  tensor([-0.002781178673694364653079524885, -0.004777404682418671770516294117])

Step=4: loss=-7.26918206536344e-05
 Input before update:  tensor([0.883345483553823584976782967715, 0.916852903735131175011474624625],
       requires_grad=True)
Input after update:  tensor([0.883629864320836122537627943530, 0.917341360183403065065022019553],
       requires_grad=True)
Gradient with respect the input:  tensor([-0.002843807670125584642628613352, -0.004884564482718539712990946100])

Step=5: loss=-7.592229197109972e-05
 Input before update:  tensor([0.883629864320836122537627943530, 0.917341360183403065065022019553],
       requires_grad=True)
Input after update:  tensor([0.883920644986479042692906205048, 0.917840768378034521646213761414],
       requires_grad=True)
Gradient with respect the input:  tensor([-0.002907806656429018105775030634, -0.004994081946314274378373454510])

Step=6: loss=-7.929937123736382e-05
 Input before update:  tensor([0.883920644986479042692906205048, 0.917840768378034521646213761414],
       requires_grad=True)
Input after update:  tensor([0.884217965562197116824449949490, 0.918351369264106320855489684618],
       requires_grad=True)
Gradient with respect the input:  tensor([-0.002973205757180271639056323707, -0.005106008860718281791579720164])

Step=7: loss=-8.282964066661698e-05
 Input before update:  tensor([0.884217965562197116824449949490, 0.918351369264106320855489684618],
       requires_grad=True)
Input after update:  tensor([0.884521969141138342251906578895, 0.918873409082966885463861217431],
       requires_grad=True)
Gradient with respect the input:  tensor([-0.003040035789411732990161763013, -0.005220398188605142146545556869])

Step=8: loss=-8.651997647392676e-05
 Input before update:  tensor([0.884521969141138342251906578895, 0.918873409082966885463861217431],
       requires_grad=True)
Input after update:  tensor([0.884832801968940652059814055974, 0.919407139492356750842816381919],
       requires_grad=True)
Gradient with respect the input:  tensor([-0.003108328278023439385918669231, -0.005337304093898763077130631416])

Step=9: loss=-9.037756203397312e-05
 Input before update:  tensor([0.884832801968940652059814055974, 0.919407139492356750842816381919],
       requires_grad=True)
Input after update:  tensor([0.885150613516077822140459829825, 0.919952817689177582138881916762],
       requires_grad=True)
Gradient with respect the input:  tensor([-0.003178115471371980096937370774, -0.005456781968208646894924473969])

Step=10: loss=-9.44099016306475e-05
 Input before update:  tensor([0.885150613516077822140459829825, 0.919952817689177582138881916762],
       requires_grad=True)
Input after update:  tensor([0.885475556551780895730985321279, 0.920510706534938272227464040043],
       requires_grad=True)
Gradient with respect the input:  tensor([-0.003249430357031136626377865184, -0.005578888457607234820090358340])

Step=11: loss=-9.862483482370327e-05
 Input before update:  tensor([0.885475556551780895730985321279, 0.920510706534938272227464040043],
       requires_grad=True)
Input after update:  tensor([0.885807787219552666968525045377, 0.921081074683912315315126306814],
       requires_grad=True)
Gradient with respect the input:  tensor([-0.003322306677718076233646327111, -0.005703681489740472509986091154])

Step=12: loss=-0.00010303055145973163
 Input before update:  tensor([0.885807787219552666968525045377, 0.921081074683912315315126306814],
       requires_grad=True)
Input after update:  tensor([0.886147465114290544541120198119, 0.921664196714038652658018691000],
       requires_grad=True)
Gradient with respect the input:  tensor([-0.003396778947379017719876426185, -0.005831220301263607616593098726])

Step=13: loss=-0.00010763560735588436
 Input before update:  tensor([0.886147465114290544541120198119, 0.921664196714038652658018691000],
       requires_grad=True)
Input after update:  tensor([0.886494753361033449579053922207, 0.922260353260598075841869558644],
       requires_grad=True)
Gradient with respect the input:  tensor([-0.003472882467428536033826613760, -0.005961565465594471230348361246])

Step=14: loss=-0.00011244894068593914
 Input before update:  tensor([0.886494753361033449579053922207, 0.922260353260598075841869558644],
       requires_grad=True)
Input after update:  tensor([0.886849818695347180685928378807, 0.922869831152695718756717724318],
       requires_grad=True)
Gradient with respect the input:  tensor([-0.003550653343136818840958257582, -0.006094778920976400525544303122])

Step=15: loss=-0.00011747988909957258
 Input before update:  tensor([0.886849818695347180685928378807, 0.922869831152695718756717724318],
       requires_grad=True)
Input after update:  tensor([0.887212831545363234120316064946, 0.923492923552580169399561782484],
       requires_grad=True)
Gradient with respect the input:  tensor([-0.003630128500160070305347037589, -0.006230923998844293924814774499])

Step=16: loss=-0.000122738207606913
 Input before update:  tensor([0.887212831545363234120316064946, 0.923492923552580169399561782484],
       requires_grad=True)
Input after update:  tensor([0.887583966115484068737373490876, 0.924129930097828733437381742988],
       requires_grad=True)
Gradient with respect the input:  tensor([-0.003711345701208666660736446019, -0.006370065452485807779015036800])

Step=17: loss=-0.00012823408726185976
 Input before update:  tensor([0.887583966115484068737373490876, 0.924129930097828733437381742988],
       requires_grad=True)
Input after update:  tensor([0.887963400471769026545132419415, 0.924781157046427937373778149777],
       requires_grad=True)
Gradient with respect the input:  tensor([-0.003794343562849391161134748884, -0.006512269485992394114914905145])

Step=18: loss=-0.00013397817467895762
 Input before update:  tensor([0.887963400471769026545132419415, 0.924781157046427937373778149777],
       requires_grad=True)
Input after update:  tensor([0.888351316629012788261832156422, 0.925446917424777248939449236786],
       requires_grad=True)
Gradient with respect the input:  tensor([-0.003879161572437443694649772397, -0.006657603783493415763872214086])

Step=19: loss=-0.00013998159242007717
 Input before update:  tensor([0.888351316629012788261832156422, 0.925446917424777248939449236786],
       requires_grad=True)
Input after update:  tensor([0.888747900639530241662100706890, 0.926127531178643992326726674946],
       requires_grad=True)
Gradient with respect the input:  tensor([-0.003965840105175015388450088238, -0.006806137538667940412029366826])

Initial position: tensor([0.882269263267517089843750000000, 0.915003955364227294921875000000]); Label: tensor([1., 0.]); Radius: 0.31835807260704385/0.15915494309189535
dl Adv ex: tensor([0.426400000000000001243449787580, 0.806200000000000027711166694644]); OutLabel: tensor([-0.007940811393449280844447635275,  0.988371787402192336635664560163],
       grad_fn=<TanhBackward>); Radius: 0.09917540000000001/0.15915494309189535
PyTorch Adv ex: tensor([0.888747900639530241662100706890, 0.926127531178643992326726674946],
       requires_grad=True); OutLabel: tensor([ 0.999531680644255127177189024223, -0.017096566835429906350274364968],
       grad_fn=<TanhBackward>); Radius: 0.33270960308004827/0.15915494309189535
