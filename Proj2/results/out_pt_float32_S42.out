Number in: 499.0, Number out: 501.0
Epoch 0: 
	Train loss: 2.50824777036905310901e-01	 Train acc: 0.46500000678002834098
	Val loss: 2.49452561140060424805e-01	 Val acc: 0.55400002002716064453
Epoch 1: 
	Train loss: 2.50349722355604153989e-01	 Train acc: 0.48300000645220281248
	Val loss: 2.48869672417640686035e-01	 Val acc: 0.62500000000000000000
Epoch 2: 
	Train loss: 2.49620888084173209176e-01	 Train acc: 0.49700000680983064116
	Val loss: 2.47698351740837097168e-01	 Val acc: 0.64399999380111694336
Epoch 3: 
	Train loss: 2.47848778963088989258e-01	 Train acc: 0.53200000591576102060
	Val loss: 2.44175344705581665039e-01	 Val acc: 0.70899999141693115234
Epoch 4: 
	Train loss: 2.41620600968599330560e-01	 Train acc: 0.60500000417232513428
	Val loss: 2.34724849462509155273e-01	 Val acc: 0.56300002336502075195
Epoch 5: 
	Train loss: 2.16199734508991242565e-01	 Train acc: 0.69000000342726708347
	Val loss: 1.85292527079582214355e-01	 Val acc: 0.71399998664855957031
Epoch 6: 
	Train loss: 1.59902655854821218462e-01	 Train acc: 0.77499999880790715334
	Val loss: 1.20461769402027130127e-01	 Val acc: 0.82300001382827758789
Epoch 7: 
	Train loss: 1.23479493558406830389e-01	 Train acc: 0.81499999761581420898
	Val loss: 8.08687284588813781738e-02	 Val acc: 0.89200001955032348633
Epoch 8: 
	Train loss: 1.05562521675601594939e-01	 Train acc: 0.84299999475479125977
	Val loss: 6.84333071112632751465e-02	 Val acc: 0.91000002622604370117
Epoch 9: 
	Train loss: 9.62861469108611395251e-02	 Train acc: 0.85299999564886097581
	Val loss: 6.80790171027183532715e-02	 Val acc: 0.90600001811981201172
Epoch 10: 
	Train loss: 8.81261035008355925191e-02	 Train acc: 0.87399999618530277434
	Val loss: 5.26234954595565795898e-02	 Val acc: 0.94099998474121093750
Epoch 11: 
	Train loss: 7.96524174034129867072e-02	 Train acc: 0.89699999213218684080
	Val loss: 5.27405254542827606201e-02	 Val acc: 0.93300002813339233398
Epoch 12: 
	Train loss: 7.25120626925490757708e-02	 Train acc: 0.90999999254941943416
	Val loss: 4.33727465569972991943e-02	 Val acc: 0.94800001382827758789
Epoch 13: 
	Train loss: 6.84257602063007702720e-02	 Train acc: 0.90799999237060546875
	Val loss: 4.43694926798343658447e-02	 Val acc: 0.93599998950958251953
Epoch 14: 
	Train loss: 6.72697846102528335122e-02	 Train acc: 0.90799999296665190318
	Val loss: 6.29761517047882080078e-02	 Val acc: 0.90299999713897705078
Epoch 15: 
	Train loss: 6.60556586540769763438e-02	 Train acc: 0.91199999451637270287
	Val loss: 4.23264168202877044678e-02	 Val acc: 0.94900000095367431641
Epoch 16: 
	Train loss: 6.16908678179606817515e-02	 Train acc: 0.91399999201297754681
	Val loss: 3.21230515837669372559e-02	 Val acc: 0.96200001239776611328
Epoch 17: 
	Train loss: 6.09761160251218806150e-02	 Train acc: 0.91699999332427983845
	Val loss: 6.42097443342208862305e-02	 Val acc: 0.90700000524520874023
Epoch 18: 
	Train loss: 5.88653797452570876070e-02	 Train acc: 0.91899999141693111682
	Val loss: 3.91331873834133148193e-02	 Val acc: 0.95099997520446777344
Epoch 19: 
	Train loss: 5.79154799558455127273e-02	 Train acc: 0.91799999237060547763
	Val loss: 3.86280603706836700439e-02	 Val acc: 0.94599997997283935547
Epoch 20: 
	Train loss: 5.02223948476603274105e-02	 Train acc: 0.93099999129772181838
	Val loss: 3.73602770268917083740e-02	 Val acc: 0.94999998807907104492
Epoch 21: 
	Train loss: 5.30626212738570732230e-02	 Train acc: 0.92399999260902410114
	Val loss: 3.16367037594318389893e-02	 Val acc: 0.95999997854232788086
Epoch 22: 
	Train loss: 5.13171200863143869841e-02	 Train acc: 0.92599999308586122826
	Val loss: 5.11114411056041717529e-02	 Val acc: 0.93599998950958251953
Epoch 23: 
	Train loss: 5.14524386273114975321e-02	 Train acc: 0.92699999332427973631
	Val loss: 3.49157378077507019043e-02	 Val acc: 0.95899999141693115234
Epoch 24: 
	Train loss: 4.75629441082128304186e-02	 Train acc: 0.93399999439716341332
	Val loss: 3.32358516752719879150e-02	 Val acc: 0.96100002527236938477
Epoch 25: 
	Train loss: 4.80910775841039139777e-02	 Train acc: 0.92999999344348904806
	Val loss: 5.44504150748252868652e-02	 Val acc: 0.92500001192092895508
Epoch 26: 
	Train loss: 5.29412345551463631166e-02	 Train acc: 0.92299999296665191650
	Val loss: 3.77269238233566284180e-02	 Val acc: 0.94900000095367431641
Epoch 27: 
	Train loss: 4.94412401685258365291e-02	 Train acc: 0.92399999201297755569
	Val loss: 3.32617573440074920654e-02	 Val acc: 0.96399998664855957031
Epoch 28: 
	Train loss: 4.43097986248903938367e-02	 Train acc: 0.93599999189376825726
	Val loss: 4.08078394830226898193e-02	 Val acc: 0.94099998474121093750
Epoch 29: 
	Train loss: 4.93807222988107211159e-02	 Train acc: 0.91999999225139617032
	Val loss: 4.78966198861598968506e-02	 Val acc: 0.93000000715255737305
Epoch 30: 
	Train loss: 4.73792944729939310977e-02	 Train acc: 0.92799999356269835538
	Val loss: 3.85763347148895263672e-02	 Val acc: 0.94199997186660766602
Epoch 31: 
	Train loss: 4.24078833586827366742e-02	 Train acc: 0.93799999237060549540
	Val loss: 3.71934026479721069336e-02	 Val acc: 0.95200002193450927734
Epoch 32: 
	Train loss: 4.15555770364881005285e-02	 Train acc: 0.94099999308586124158
	Val loss: 2.81212236732244491577e-02	 Val acc: 0.96799999475479125977
Epoch 33: 
	Train loss: 4.24037745729583526177e-02	 Train acc: 0.94099999427795411044
	Val loss: 3.30946967005729675293e-02	 Val acc: 0.94599997997283935547
Epoch 34: 
	Train loss: 4.18448805119260233698e-02	 Train acc: 0.94199999272823331520
	Val loss: 2.68767233937978744507e-02	 Val acc: 0.96399998664855957031
Epoch 35: 
	Train loss: 4.19587098545525782889e-02	 Train acc: 0.93899999320507054890
	Val loss: 3.25161777436733245850e-02	 Val acc: 0.95700001716613769531
Epoch 36: 
	Train loss: 4.20003774576616709102e-02	 Train acc: 0.93899999260902400344
	Val loss: 3.35045345127582550049e-02	 Val acc: 0.96299999952316284180
Epoch 37: 
	Train loss: 4.29766134396413687635e-02	 Train acc: 0.93899999320507054890
	Val loss: 3.21084707975387573242e-02	 Val acc: 0.95399999618530273438
Epoch 38: 
	Train loss: 4.23974226581776761358e-02	 Train acc: 0.93799999296665192983
	Val loss: 4.01806198060512542725e-02	 Val acc: 0.93599998950958251953
Epoch 39: 
	Train loss: 3.91008443918326523137e-02	 Train acc: 0.94599999368190768045
	Val loss: 4.16263826191425323486e-02	 Val acc: 0.94700002670288085938
Epoch 40: 
	Train loss: 3.69321085221235995144e-02	 Train acc: 0.94499999284744262695
	Val loss: 6.57703354954719543457e-02	 Val acc: 0.91100001335144042969
Epoch 41: 
	Train loss: 3.76627620711951771604e-02	 Train acc: 0.94599999129772183171
	Val loss: 3.59156988561153411865e-02	 Val acc: 0.94499999284744262695
Epoch 42: 
	Train loss: 3.56156474343879356215e-02	 Train acc: 0.94999999403953550026
	Val loss: 2.98772025853395462036e-02	 Val acc: 0.95899999141693115234
Epoch 43: 
	Train loss: 3.99997529776737817397e-02	 Train acc: 0.93999999165534975365
	Val loss: 2.90737729519605636597e-02	 Val acc: 0.96200001239776611328
Epoch 44: 
	Train loss: 3.34912184774293561484e-02	 Train acc: 0.95099999308586125046
	Val loss: 3.74069325625896453857e-02	 Val acc: 0.94499999284744262695
Epoch 45: 
	Train loss: 3.53281456617696651423e-02	 Train acc: 0.95099999308586125046
	Val loss: 2.57043018937110900879e-02	 Val acc: 0.96700000762939453125
Epoch 46: 
	Train loss: 3.56165504875752964020e-02	 Train acc: 0.95099999368190768489
	Val loss: 2.81244069337844848633e-02	 Val acc: 0.97799998521804809570
Epoch 47: 
	Train loss: 3.30356297115213248805e-02	 Train acc: 0.95599999427795412377
	Val loss: 4.50232774019241333008e-02	 Val acc: 0.94099998474121093750
Epoch 48: 
	Train loss: 3.66008069140843841915e-02	 Train acc: 0.94599999368190768045
	Val loss: 2.90740951895713806152e-02	 Val acc: 0.96499997377395629883
Epoch 49: 
	Train loss: 3.34402749514265476560e-02	 Train acc: 0.95399999260902401677
	Val loss: 2.98745296895503997803e-02	 Val acc: 0.96700000762939453125

==> End of training after 3.9539942741394043 seconds. Generating a new test set

Final test loss: 0.025	Final test acc: 0.97	Final test error 0.03

Step=0: loss=-0.0010604556882753968
 Input before update:  tensor([0.38286, 0.95931], requires_grad=True)
Input after update:  tensor([0.38301, 0.95170], requires_grad=True)
Gradient with respect the input:  tensor([-0.00145,  0.07601])

Step=1: loss=-0.0018261485965922475
 Input before update:  tensor([0.38301, 0.95170], requires_grad=True)
Input after update:  tensor([0.38323, 0.93869], requires_grad=True)
Gradient with respect the input:  tensor([-0.00221,  0.13010])

Step=2: loss=-0.004564283415675163
 Input before update:  tensor([0.38323, 0.93869], requires_grad=True)
Input after update:  tensor([0.38377, 0.90702], requires_grad=True)
Gradient with respect the input:  tensor([-0.00537,  0.31679])

Step=3: loss=-0.07203517854213715
 Input before update:  tensor([0.38377, 0.90702], requires_grad=True)
Input after update:  tensor([0.51497, 0.41980], requires_grad=True)
Gradient with respect the input:  tensor([-1.31201,  4.87215])

Step=4: loss=-0.998039960861206
 Input before update:  tensor([0.51497, 0.41980], requires_grad=True)
Input after update:  tensor([0.51515, 0.41973], requires_grad=True)
Gradient with respect the input:  tensor([-0.00178,  0.00072])

Step=5: loss=-0.9980402588844299
 Input before update:  tensor([0.51515, 0.41973], requires_grad=True)
Input after update:  tensor([0.51532, 0.41966], requires_grad=True)
Gradient with respect the input:  tensor([-0.00178,  0.00072])

Step=6: loss=-0.9980406761169434
 Input before update:  tensor([0.51532, 0.41966], requires_grad=True)
Input after update:  tensor([0.51550, 0.41959], requires_grad=True)
Gradient with respect the input:  tensor([-0.00178,  0.00072])

Step=7: loss=-0.998041033744812
 Input before update:  tensor([0.51550, 0.41959], requires_grad=True)
Input after update:  tensor([0.51568, 0.41951], requires_grad=True)
Gradient with respect the input:  tensor([-0.00178,  0.00072])

Step=8: loss=-0.9980414509773254
 Input before update:  tensor([0.51568, 0.41951], requires_grad=True)
Input after update:  tensor([0.51586, 0.41944], requires_grad=True)
Gradient with respect the input:  tensor([-0.00178,  0.00072])

Step=9: loss=-0.9980417490005493
 Input before update:  tensor([0.51586, 0.41944], requires_grad=True)
Input after update:  tensor([0.51604, 0.41937], requires_grad=True)
Gradient with respect the input:  tensor([-0.00178,  0.00072])

Step=10: loss=-0.9980422258377075
 Input before update:  tensor([0.51604, 0.41937], requires_grad=True)
Input after update:  tensor([0.51621, 0.41930], requires_grad=True)
Gradient with respect the input:  tensor([-0.00178,  0.00072])

Step=11: loss=-0.9980425238609314
 Input before update:  tensor([0.51621, 0.41930], requires_grad=True)
Input after update:  tensor([0.51639, 0.41923], requires_grad=True)
Gradient with respect the input:  tensor([-0.00178,  0.00072])

Step=12: loss=-0.9980428218841553
 Input before update:  tensor([0.51639, 0.41923], requires_grad=True)
Input after update:  tensor([0.51657, 0.41916], requires_grad=True)
Gradient with respect the input:  tensor([-0.00178,  0.00072])

Step=13: loss=-0.9980432987213135
 Input before update:  tensor([0.51657, 0.41916], requires_grad=True)
Input after update:  tensor([0.51675, 0.41908], requires_grad=True)
Gradient with respect the input:  tensor([-0.00178,  0.00072])

Step=14: loss=-0.9980435967445374
 Input before update:  tensor([0.51675, 0.41908], requires_grad=True)
Input after update:  tensor([0.51693, 0.41901], requires_grad=True)
Gradient with respect the input:  tensor([-0.00178,  0.00072])

Initial position: tensor([0.38286, 0.95931]); Label: tensor([1., 0.]); Radius: 0.22468256950378418/0.15915494309189535
dl Adv ex: tensor([0.37226, 0.97050]); OutLabel: tensor([0.98151, 0.01968], grad_fn=<SigmoidBackward>); Radius: 0.23768775165081024/0.15915494309189535
PyTorch Adv ex: tensor([0.51693, 0.41901], requires_grad=True); OutLabel: tensor([0.00107, 0.99911], grad_fn=<SigmoidBackward>); Radius: 0.00684547983109951/0.15915494309189535
