Number in: 499.0, Number out: 501.0
Epoch 0: 
	Train loss: 2.51041624277701713730e-01	 Train acc: 0.49500000752508638291
	Val loss: 2.49362100231482475277e-01	 Val acc: 0.50499999523162841797
Epoch 1: 
	Train loss: 2.50088621782609710209e-01	 Train acc: 0.49500000722706316569
	Val loss: 2.48609160914950166887e-01	 Val acc: 0.61000001430511474609
Epoch 2: 
	Train loss: 2.48976082031030554464e-01	 Train acc: 0.51900000713765626070
	Val loss: 2.46671280429686584634e-01	 Val acc: 0.65200001001358032227
Epoch 3: 
	Train loss: 2.45262191016025782320e-01	 Train acc: 0.57500000581145283007
	Val loss: 2.39489620800399621858e-01	 Val acc: 0.64600002765655517578
Epoch 4: 
	Train loss: 2.27680678783032136581e-01	 Train acc: 0.66100000075995923865
	Val loss: 2.17678941225390359948e-01	 Val acc: 0.57899999618530273438
Epoch 5: 
	Train loss: 1.80668711883250482364e-01	 Train acc: 0.72900000073015691626
	Val loss: 1.79137064647772847881e-01	 Val acc: 0.68800002336502075195
Epoch 6: 
	Train loss: 1.36177260502688024513e-01	 Train acc: 0.80299999654293063855
	Val loss: 1.08417253047849687642e-01	 Val acc: 0.84899997711181640625
Epoch 7: 
	Train loss: 1.11607733375803555576e-01	 Train acc: 0.83399999260902402121
	Val loss: 9.70400045956374829315e-02	 Val acc: 0.85699999332427978516
Epoch 8: 
	Train loss: 9.53514129045203856494e-02	 Train acc: 0.86599999189376830611
	Val loss: 1.07629910802025385852e-01	 Val acc: 0.83399999141693115234
Epoch 9: 
	Train loss: 8.47989545580611486786e-02	 Train acc: 0.88899999380111693892
	Val loss: 8.75723569723850514546e-02	 Val acc: 0.87500000000000000000
Epoch 10: 
	Train loss: 8.54602227848236806196e-02	 Train acc: 0.87999999344348911468
	Val loss: 6.20709581067488275208e-02	 Val acc: 0.90899997949600219727
Epoch 11: 
	Train loss: 8.75210036769773075394e-02	 Train acc: 0.87799999207258228040
	Val loss: 6.68395149751061512511e-02	 Val acc: 0.91799998283386230469
Epoch 12: 
	Train loss: 7.70387496342424121787e-02	 Train acc: 0.89899999290704724064
	Val loss: 5.99888659899356219141e-02	 Val acc: 0.92100000381469726562
Epoch 13: 
	Train loss: 6.79388520421454200626e-02	 Train acc: 0.91499999344348903474
	Val loss: 6.46175745390623057496e-02	 Val acc: 0.90600001811981201172
Epoch 14: 
	Train loss: 6.18003878562244438055e-02	 Train acc: 0.91699999153614042413
	Val loss: 5.80540745128210189385e-02	 Val acc: 0.91500002145767211914
Epoch 15: 
	Train loss: 6.21560137356960695776e-02	 Train acc: 0.91499999403953546917
	Val loss: 5.64452660440360257099e-02	 Val acc: 0.91799998283386230469
Epoch 16: 
	Train loss: 6.07349936871188142429e-02	 Train acc: 0.91399999439716339555
	Val loss: 5.23952466513964154604e-02	 Val acc: 0.92599999904632568359
Epoch 17: 
	Train loss: 6.11801626403136039611e-02	 Train acc: 0.91399999201297754681
	Val loss: 5.42163950056761545504e-02	 Val acc: 0.92199999094009399414
Epoch 18: 
	Train loss: 5.55665153096263492172e-02	 Train acc: 0.92299999177455904764
	Val loss: 4.03593214280205392352e-02	 Val acc: 0.94599997997283935547
Epoch 19: 
	Train loss: 5.47774840852656430545e-02	 Train acc: 0.92199999332427973187
	Val loss: 6.09836233083616771622e-02	 Val acc: 0.92199999094009399414
Epoch 20: 
	Train loss: 4.75187437086642266992e-02	 Train acc: 0.93999999165534975365
	Val loss: 4.64573076115187000301e-02	 Val acc: 0.93900001049041748047
Epoch 21: 
	Train loss: 5.83255421090952894114e-02	 Train acc: 0.91699999213218685856
	Val loss: 5.35398805365406640910e-02	 Val acc: 0.93199998140335083008
Epoch 22: 
	Train loss: 5.40556764317052587665e-02	 Train acc: 0.92699999451637271619
	Val loss: 5.74182003372471841396e-02	 Val acc: 0.93000000715255737305
Epoch 23: 
	Train loss: 5.12021498787985779311e-02	 Train acc: 0.92799999415874478981
	Val loss: 4.60035744673179189390e-02	 Val acc: 0.93500000238418579102
Epoch 24: 
	Train loss: 5.04587196072091501153e-02	 Train acc: 0.93199999272823330632
	Val loss: 4.06701850320518309978e-02	 Val acc: 0.95200002193450927734
Epoch 25: 
	Train loss: 5.01920267760075644592e-02	 Train acc: 0.92899999260902399456
	Val loss: 4.09900619330895374381e-02	 Val acc: 0.95200002193450927734
Epoch 26: 
	Train loss: 5.07420311127179876620e-02	 Train acc: 0.93199999392032628620
	Val loss: 3.91248386563662203796e-02	 Val acc: 0.94900000095367431641
Epoch 27: 
	Train loss: 5.25022935592101419600e-02	 Train acc: 0.92199999213218686300
	Val loss: 4.84083088640458042429e-02	 Val acc: 0.93900001049041748047
Epoch 28: 
	Train loss: 4.26816725521429532475e-02	 Train acc: 0.94099999189376826170
	Val loss: 4.53036902246350334234e-02	 Val acc: 0.92900002002716064453
Epoch 29: 
	Train loss: 4.63289783258394663457e-02	 Train acc: 0.93599999547004697487
	Val loss: 4.41553355651139317617e-02	 Val acc: 0.93599998950958251953
Epoch 30: 
	Train loss: 4.30030259560565120136e-02	 Train acc: 0.94399999320507044231
	Val loss: 3.87858962443537250153e-02	 Val acc: 0.94499999284744262695
Epoch 31: 
	Train loss: 5.01675828061343143105e-02	 Train acc: 0.92699999451637271619
	Val loss: 3.64399335389182232881e-02	 Val acc: 0.94900000095367431641
Epoch 32: 
	Train loss: 4.81002908039055709910e-02	 Train acc: 0.92999999105930331034
	Val loss: 4.57443835210048985185e-02	 Val acc: 0.93099999427795410156
Epoch 33: 
	Train loss: 4.42060844860554455482e-02	 Train acc: 0.93899999499320985219
	Val loss: 3.60237152618148176453e-02	 Val acc: 0.95099997520446777344
Epoch 34: 
	Train loss: 4.14662429613715938226e-02	 Train acc: 0.94199998974800114304
	Val loss: 2.83636037989460770836e-02	 Val acc: 0.96700000762939453125
Epoch 35: 
	Train loss: 4.06645613975606251556e-02	 Train acc: 0.94599999308586124602
	Val loss: 3.03919831970250187148e-02	 Val acc: 0.95399999618530273438
Epoch 36: 
	Train loss: 4.05038471183221462923e-02	 Train acc: 0.94399999260902400788
	Val loss: 3.61330248177450796820e-02	 Val acc: 0.95300000905990600586
Epoch 37: 
	Train loss: 4.47809814386910323702e-02	 Train acc: 0.93799999415874479869
	Val loss: 5.83622348343248026348e-02	 Val acc: 0.92299997806549072266
Epoch 38: 
	Train loss: 3.82310158020871537765e-02	 Train acc: 0.94699999451637273395
	Val loss: 6.21369142912522876010e-02	 Val acc: 0.90799999237060546875
Epoch 39: 
	Train loss: 4.26621502007393724187e-02	 Train acc: 0.93699999272823331076
	Val loss: 4.14179146970681255624e-02	 Val acc: 0.94300001859664916992
Epoch 40: 
	Train loss: 4.25723727638005478013e-02	 Train acc: 0.93799999296665192983
	Val loss: 3.18971686960169489855e-02	 Val acc: 0.95200002193450927734
Epoch 41: 
	Train loss: 3.52006123848829233225e-02	 Train acc: 0.94999999403953550026
	Val loss: 3.76124996685515064487e-02	 Val acc: 0.94499999284744262695
Epoch 42: 
	Train loss: 3.98411027358507030538e-02	 Train acc: 0.94199999332427974963
	Val loss: 1.06213354598075099267e-01	 Val acc: 0.85900002717971801758
Epoch 43: 
	Train loss: 3.34952041643207451549e-02	 Train acc: 0.95099999368190768489
	Val loss: 3.14409008760293401386e-02	 Val acc: 0.94599997997283935547
Epoch 44: 
	Train loss: 3.32501094501969143846e-02	 Train acc: 0.95099999189376827058
	Val loss: 4.31112926274930391424e-02	 Val acc: 0.93800002336502075195
Epoch 45: 
	Train loss: 3.49150868819015219868e-02	 Train acc: 0.95699999511241917727
	Val loss: 3.50709360406068204608e-02	 Val acc: 0.95399999618530273438
Epoch 46: 
	Train loss: 4.23833758602062682375e-02	 Train acc: 0.94099999248981480715
	Val loss: 4.09198914670459504284e-02	 Val acc: 0.93900001049041748047
Epoch 47: 
	Train loss: 3.50364274800566005696e-02	 Train acc: 0.95299999237060550872
	Val loss: 3.72818009429234653584e-02	 Val acc: 0.95099997520446777344
Epoch 48: 
	Train loss: 3.44445234028304889118e-02	 Train acc: 0.95399999260902401677
	Val loss: 2.28413205356119280998e-02	 Val acc: 0.97500002384185791016
Epoch 49: 
	Train loss: 3.08428098522597372855e-02	 Train acc: 0.95599999248981470945
	Val loss: 3.06564357471820446432e-02	 Val acc: 0.96499997377395629883

==> End of training after 3.835824489593506 seconds. Generating a new test set

Final test loss: 0.025	Final test acc: 0.98	Final test error 0.02

Step=0: loss=-0.0020099868423677832
 Input before update:  tensor([0.38286, 0.95931], requires_grad=True)
Input after update:  tensor([0.38596, 0.94964], requires_grad=True)
Gradient with respect the input:  tensor([-0.03092,  0.09664])

Step=1: loss=-0.003343468895130192
 Input before update:  tensor([0.38596, 0.94964], requires_grad=True)
Input after update:  tensor([0.39103, 0.93378], requires_grad=True)
Gradient with respect the input:  tensor([-0.05073,  0.15857])

Step=2: loss=-0.007831623053359296
 Input before update:  tensor([0.39103, 0.93378], requires_grad=True)
Input after update:  tensor([0.40383, 0.89467], requires_grad=True)
Gradient with respect the input:  tensor([-0.12800,  0.39110])

Step=3: loss=-0.19200807106487033
 Input before update:  tensor([0.40383, 0.89467], requires_grad=True)
Input after update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Gradient with respect the input:  tensor([-6.66689, 15.18573])

Step=4: loss=-5.797108483236324e-40
 Input before update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Input after update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Gradient with respect the input:  tensor([ 4.24853e-39, -7.36092e-38])

Step=5: loss=-5.797108483236324e-40
 Input before update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Input after update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Gradient with respect the input:  tensor([ 4.24853e-39, -7.36092e-38])

Step=6: loss=-5.797108483236324e-40
 Input before update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Input after update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Gradient with respect the input:  tensor([ 4.24853e-39, -7.36092e-38])

Step=7: loss=-5.797108483236324e-40
 Input before update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Input after update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Gradient with respect the input:  tensor([ 4.24853e-39, -7.36092e-38])

Step=8: loss=-5.797108483236324e-40
 Input before update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Input after update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Gradient with respect the input:  tensor([ 4.24853e-39, -7.36092e-38])

Step=9: loss=-5.797108483236324e-40
 Input before update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Input after update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Gradient with respect the input:  tensor([ 4.24853e-39, -7.36092e-38])

Step=10: loss=-5.797108483236324e-40
 Input before update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Input after update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Gradient with respect the input:  tensor([ 4.24853e-39, -7.36092e-38])

Step=11: loss=-5.797108483236324e-40
 Input before update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Input after update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Gradient with respect the input:  tensor([ 4.24853e-39, -7.36092e-38])

Step=12: loss=-5.797108483236324e-40
 Input before update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Input after update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Gradient with respect the input:  tensor([ 4.24853e-39, -7.36092e-38])

Step=13: loss=-5.797108483236324e-40
 Input before update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Input after update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Gradient with respect the input:  tensor([ 4.24853e-39, -7.36092e-38])

Step=14: loss=-5.797108483236324e-40
 Input before update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Input after update:  tensor([ 1.07052, -0.62390], requires_grad=True)
Gradient with respect the input:  tensor([ 4.24853e-39, -7.36092e-38])

Initial position: tensor([0.38286, 0.95931]); Label: tensor([1., 0.]); Radius: 0.22468257336534236/0.15915494309189535
dl Adv ex: tensor([0.37226, 0.97050]); OutLabel: tensor([0.96861, 0.03160], grad_fn=<SigmoidBackward>); Radius: 0.23768775760000002/0.15915494309189535
PyTorch Adv ex: tensor([ 1.07052, -0.62390], requires_grad=True); OutLabel: tensor([1.00000e+00, 3.40503e-20], grad_fn=<SigmoidBackward>); Radius: 1.5886381969180512/0.15915494309189535
